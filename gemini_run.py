import sys
import os
import toml
import google.generativeai as genai

# --- ì„¤ì • ---
CONFIG_PATH = os.path.expanduser("~/.config/gemini-cli.toml")

def get_api_key():
    try:
        config = toml.load(CONFIG_PATH)
        return config['gemini'].get('token') or config['gemini'].get('api_key')
    except Exception:
        return None

def chat(prompt):
    api_key = get_api_key()
    if not api_key:
        print(f"âŒ ì„¤ì • íŒŒì¼({CONFIG_PATH})ì—ì„œ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    genai.configure(api_key=api_key)
    
    # â˜… ì—¬ê¸°ê°€ í•µì‹¬ ë³€ê²½ì‚¬í•­ìž…ë‹ˆë‹¤ â˜…
    # ì‚¬ìš©ìžë‹˜ ëª©ë¡ì— ìžˆëŠ” ìµœì‹  ëª¨ë¸ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì‹œë„í•©ë‹ˆë‹¤.
    models_to_try = [
        'gemini-2.5-flash',       # ìµœì‹  2.5 ë²„ì „ (ê°€ìž¥ ì¶”ì²œ)
        'gemini-2.0-flash',       # 2.0 ë²„ì „
        'gemini-flash-latest',    # ìµœì‹  í”Œëž˜ì‹œ ìžë™ ì„ íƒ
        'gemini-1.5-flash'        # êµ¬ë²„ì „ (ì˜ˆë¹„ìš©)
    ]
    
    for model_name in models_to_try:
        try:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            print(f"\nðŸ¤– Gemini ({model_name}):\n{response.text}")
            return
        except Exception as e:
            if "404" in str(e) or "not found" in str(e).lower():
                continue # ë‹¤ìŒ ëª¨ë¸ ì‹œë„
            else:
                print(f"âŒ Error with {model_name}: {e}")
                return

    print("\nâŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    if len(sys.argv) > 1:
        user_input = " ".join(sys.argv[1:])
        chat(user_input)
    else:
        print("ì‚¬ìš©ë²•: python gemini_run.py [ì§ˆë¬¸]")